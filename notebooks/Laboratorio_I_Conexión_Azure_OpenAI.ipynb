{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conexión Básica a los Servicios de OpenAI\n",
        "## Objetivos\n",
        "\n",
        "El proposito de este taller es presentar las funcionalidades básicas y modelos de OpenAI.\n",
        "\n",
        "Este notebook esta basado en la documentación oficial:\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bzWCFEynURQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1. Interacción básica"
      ],
      "metadata": {
        "id": "qowXDlhRItpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1\n",
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Yap96FJEPs",
        "outputId": "1d25f6f5-028b-4a82-bf6e-71ff0028c2ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/77.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key  = \"2dee58cbba95482eb16dc0f93577c197\"\n",
        "openai.api_base = \"https://openaiuniandesdevtest.openai.azure.com/\"\n",
        "openai.api_type = 'azure'\n",
        "openai.api_version = '2023-05-15'\n",
        "engine='gpt-turbo-RF-NT' #model"
      ],
      "metadata": {
        "id": "MJ64_PSaI3z9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A lo largo de este notebook, utilizaremos el modelo gpt-3.5-turbo de OpenAI y el endpoint de chatcompletion.\n",
        "\n",
        "Esta función auxiliar facilitará el uso de indicaciones y la visualización de las salidas generadas:"
      ],
      "metadata": {
        "id": "08CkifqFJ-4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fuentes 2023-11\n",
        "#https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line&pivots=programming-language-python\n",
        "#https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python\n",
        "#https://platform.openai.com/docs/api-reference/completions\n",
        "\n",
        "def get_completion(prompt, engine=\"gpt-turbo-RF-NT\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=engine,\n",
        "        messages=messages,\n",
        "        temperature=0.5, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "JQsq49mLJqGW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting\n",
        "\n",
        "Prompting es la forma en que los seres humanos pueden comunicarse con las inteligencias artificiales. Es una manera de decirle a la IA qué queremos y cómo lo queremos, generalmente utilizando palabras. La ingeniería de prompts es la tarea de encontrar la indicación (texto de entrada) que obtiene los mejores resultados de la IA.\n",
        "\n",
        "\n",
        "## Estrategias básicas para Prompting\n",
        "- Escribir instrucciones claras\n",
        "- Use delimitadores para indicar claramente las distintas partes de la entrada. Los delimitadores pueden ser: ```, \"\"\", < >, `<tag> </tag>`, `:`\n"
      ],
      "metadata": {
        "id": "4LuDaVN0K7ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Consideremos el ejercicio de resumir un texto de entrada\n",
        "\n",
        "text = f\"\"\"\n",
        "El aprendizaje automático (AA) o aprendizaje automatizado o aprendizaje \\\n",
        "de máquinas o aprendizaje computacional (del inglés, machine learning) \\\n",
        "es el subcampo de las ciencias de la computación y una rama de la inteligencia artificial, \\\n",
        "cuyo objetivo es desarrollar técnicas que permitan que las computadoras aprendan. \\\n",
        "Se dice que un agente aprende cuando su desempeño mejora con la experiencia y mediante el uso de datos; \\\n",
        "es decir, cuando la habilidad no estaba presente en su genotipo o rasgos de nacimiento. \\\n",
        "En el aprendizaje de máquinas un computador observa datos,  \\\n",
        "construye un modelo basado en esos datos y utiliza ese modelo a la vez como \\\n",
        "una hipótesis acerca del mundo y una pieza de software que puede resolver problemas. \\\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Resume el texto delimitado por triple backticks en una sola oración.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8VOwN0I_JP",
        "outputId": "f0eeec97-cb6c-4255-b097-f883a3f801f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El aprendizaje automático es un subcampo de las ciencias de la computación y de la inteligencia artificial que busca desarrollar técnicas para que las computadoras aprendan y mejoren su desempeño a través del uso de datos y la experiencia, construyendo modelos que les permitan resolver problemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los prompts pueden ser tan sofisticados como uno quiera, sin embargo entre mas sofisiticados con mayor claridad deben ser escritos. Una buena estrategia para construir prompts de calidad en tareas complejas es descomponer la tarea en tareas mas pequeñas ordenadas. Veamos un ejemplo."
      ],
      "metadata": {
        "id": "4mXJKjq50FXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "A lo largo del día, y luego de conocerse el fallo donde la Corte Internacional de Justicia (CIJ) rechazó la petición de Nicaragua de extender su plataforma continental más allá de 200 millas náuticas desde su costa, reaccionaron todos los expresidentes vivos de Colombia.\\\n",
        "Nicaragua no tiene derecho a una línea extendida dentro de las 200 millas de la línea base de Colombia. Dentro de la línea base de las millas náuticas de San Andrés y Providencia, Nicaragua no tiene derechos a una plataforma extendida, leyó Joan Donoghue, presidenta de la Corte de La Haya.\\\n",
        "Es de recordar que Colombia y Nicaragua son viejos conocidos en la disputa por el mar. En total, a la Corte Internacional de Justicia (CIJ) han llegado tres demandas y en dos de esas Colombia no salió tan bien librado, pues ya ha perdido parte de sus aguas con el país centroamericano. Eso sí, hay que resaltar que sigue con la plena jurisdicción de las islas de San Andrés y Providencia.\\\n",
        "Iván Duque: Colombia ha defendido su soberanía a pesar de haberse retirado de la competencia de la CIJ, luego de su injusto fallo de 2012. Quiero felicitar a Manuel José Cepeda, Carlos Gustavo Arrieta, al equipo de la Cancillería y la Armada Nacional; al igual que a los asesores del equipo de Defensa, que desvirtuaron los argumentos de Nicaragua en su absurda pretensión de Plataforma Continental Extendida.\\\n",
        "Juan Manuel Santos: Gran triunfo de Colombia. Felicitaciones a la Canciller Holguín y a todos los que hicieron posible este gran logro diplomático jurídico en La Haya para nuestro país. Se cierra un capítulo luego de 10 años de litigio que sumados a los otros once del primer proceso de Nicaragua contra Colombia por la soberanía territorial y delimitación marítima, concluyen más de dos décadas de pleitos judiciales entre los dos países.\\\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Realice las siguientes acciones:\n",
        "1 - Resume el siguiente texto delimitado por triple backticks en 1 oración.\n",
        "2 - Traducir el resumen al francés.\n",
        "3 - Enumere cada nombres de organziaciones o paises presentes en el resumen en francés.\n",
        "4 - Muestra un objeto json que contiene lo siguiente \\\n",
        "keys: resumen_frances, numero_de_nombres.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdspTyT00uD6",
        "outputId": "814f9c5f-dbd8-4ebb-bc1b-ab80fc4c2148"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La Corte Internacional de Justicia rechaza la petición de Nicaragua de extender su plataforma continental más allá de 200 millas náuticas desde su costa, lo que es considerado un gran logro diplomático jurídico para Colombia por los expresidentes vivos del país. \n",
            "\n",
            "La Cour internationale de justice rejette la demande du Nicaragua d'étendre sa plate-forme continentale au-delà de 200 milles nautiques de sa côte, considérée comme une grande réussite diplomatique juridique pour la Colombie par les anciens présidents vivants du pays. \n",
            "\n",
            "Organisations/pays: Corte Internacional de Justicia (CIJ), Nicaragua, Colombie, Cour de La Haya. \n",
            "\n",
            "{\n",
            "\"resumen_frances\": \"La Cour internationale de justice rejette la demande du Nicaragua d'étendre sa plate-forme continentale au-delà de 200 milles nautiques de sa côte, considérée comme une grande réussite diplomatique juridique pour la Colombie par les anciens présidents vivants du pays.\",\n",
            "\"numero_de_nombres\": 4\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeral A\n",
        "\n",
        "Escriba un prompt que realice las siguientes operaciones sobre un texto en ingles de maximo un parrafo:\n",
        "- Lo traduzca a español con tono informal.\n",
        "- Identifique y liste los verbos en el texto traducido.\n",
        "- Devuelva un objeto Json con la traducción y la lista de verbos."
      ],
      "metadata": {
        "id": "7VZ6tfK4xwP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "English is a West Germanic language in the Indo-European language family, whose speakers, called Anglophones, originated in early medieval England.\\\n",
        "The namesake of the language is the Angles, one of the ancient Germanic peoples that migrated to the island of Great Britain. \\\n",
        "Modern English is both the most spoken language in the world and the third-most spoken native language, after Mandarin Chinese and Spanish.\\\n",
        "It is also the most widely learned second language in the world, with more second-language speakers than native speakers.\\\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Do the following:\n",
        "1 - Translate the text to informal spanish.\n",
        "2 - Identify the verbs within the translated text.\n",
        "3 - Return a json object with the translation and a list with all the verbs\n",
        "keys: traduccion_espanol, verbos.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "8PIw8ozE2Q_8",
        "outputId": "5b3b1551-922d-4a43-f1d4-0d1d528501b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\"traduccion_espanol\": \"El inglés es un idioma germánico occidental de la familia de lenguas indoeuropeas, cuyos hablantes, llamados angloparlantes, se originaron en la Inglaterra medieval temprana. El nombre del idioma es Anglos, uno de los antiguos pueblos germánicos que migraron a la isla de Gran Bretaña. El inglés moderno es tanto el idioma más hablado en el mundo como el tercer idioma nativo más hablado, después del chino mandarín y el español. También es el segundo idioma más aprendido en el mundo, con más hablantes de segundo idioma que hablantes nativos.\",\n",
            "\"verbos\": [\"es\", \"llamados\", \"originaron\", \"migraron\", \"hablado\", \"hablado\", \"es\", \"aprendido\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Usar esta celda para entregar numeral A\n",
        "\n",
        "text = f\"\"\"\n",
        "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms \\\n",
        "that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks  \\\n",
        "have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models,  \\\n",
        "computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks. \\\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Realice las siguientes acciones: \\\n",
        "1 - Traduzca a español el texto delimitado por triple backticks.\\\n",
        "2 - Identifique y liste los verbos del texto traducido.\\\n",
        "3 - Muestra un objeto json que contiene lo siguiente \\\n",
        "keys: spanish_summary, verbs_list.\\\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "id": "tkW7ECkDxvhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89bb5f40-7544-404d-f364-ca4303ee6bfe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto traducido:\n",
            "El aprendizaje automático (ML) es un campo de estudio en inteligencia artificial que se preocupa por el desarrollo y estudio de algoritmos estadísticos que puedan generalizar efectivamente y, por lo tanto, realizar tareas sin instrucciones explícitas. Recientemente, las redes neuronales artificiales generativas han podido superar muchos enfoques anteriores en rendimiento. Los enfoques de aprendizaje automático se han aplicado a grandes modelos de lenguaje, visión por computadora, reconocimiento de voz, filtrado de correo electrónico, agricultura y medicina, donde es demasiado costoso desarrollar algoritmos para realizar las tareas necesarias.\n",
            "\n",
            "Verbos: \n",
            "- preocuparse\n",
            "- desarrollar\n",
            "- estudiar\n",
            "- generalizar\n",
            "- realizar\n",
            "- superar\n",
            "- aplicar\n",
            "- filtrar\n",
            "- costar\n",
            "- necesitar\n",
            "\n",
            "Objeto JSON:\n",
            "{\n",
            "  \"spanish_summary\": \"El aprendizaje automático (ML) es un campo de estudio en inteligencia artificial que se preocupa por el desarrollo y estudio de algoritmos estadísticos que puedan generalizar efectivamente y, por lo tanto, realizar tareas sin instrucciones explícitas. Recientemente, las redes neuronales artificiales generativas han podido superar muchos enfoques anteriores en rendimiento. Los enfoques de aprendizaje automático se han aplicado a grandes modelos de lenguaje, visión por computadora, reconocimiento de voz, filtrado de correo electrónico, agricultura y medicina, donde es demasiado costoso desarrollar algoritmos para realizar las tareas necesarias.\",\n",
            "  \"verbs_list\": [\"preocuparse\", \"desarrollar\", \"estudiar\", \"generalizar\", \"realizar\", \"superar\", \"aplicar\", \"filtrar\", \"costar\", \"necesitar\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few Shot Learning\n",
        "\n",
        "Vamos a construir un clasificador por medio de un modelo de lenguaje. Para eso vamos a darle un pequeño conjunto de ejemplos en el prompt. A esta estrategia se le conoce como \"few shot\"."
      ],
      "metadata": {
        "id": "TX43LT6C3s66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Hagamos un extractor de entidades nombradas, le damos unos pocos ejemplos y la oración de interes al final\n",
        "prompt = f\"\"\"\n",
        "[Texto]: Fred es un emprendedor en serie. Cofundador y director ejecutivo de Platform.sh, anteriormente cofundó Commerce Guys, un proveedor líder de comercio electrónico de Drupal. Su misión es garantizar que mientras continuamos en un viaje ambicioso para transformar profundamente la forma en que se usa y se percibe la computación en la nube, mantenemos los pies bien puestos en el suelo y continuamos con el rápido crecimiento que hemos disfrutado hasta ahora.\n",
        "[Nombre]: Fred\n",
        "[Puesto]: Co-fundador y CEO\n",
        "[Empresa]: Platform.sh\n",
        "###\n",
        "[Texto]: Microsoft (la palabra es un acrónimo de \"software de microcomputadora\") fue fundado por Bill Gates el 4 de abril de 1975 para desarrollar y vender intérpretes BASIC para Altair 8800. Steve Ballmer reemplazó a Gates como director ejecutivo en 2000 y luego imaginó una estrategia de \"dispositivos y servicios\".\n",
        "[Nombre]: Steve Ballmer\n",
        "[Puesto]: director general\n",
        "[Empresa]: Microsoft\n",
        "###\n",
        "[Texto]: Franck Riboud nació el 7 de noviembre de 1955 en Lyon. Es hijo de Antoine Riboud, el anterior director ejecutivo, que transformó al antiguo fabricante de vidrio europeo BSN Group en un actor líder en la industria alimentaria. Es el director general de Danone.\n",
        "[Nombre]: Franck Riboud\n",
        "[Puesto]: director general\n",
        "[Empresa]: Danone\n",
        "###\n",
        "[Texto]: David Melvin es un profesional de servicios financieros y de inversión en CITIC CLSA con más de 30 años de experiencia en banca de inversión y capital privado. Actualmente es Consejero Senior de CITIC CLSA\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "## Nota: Cobran por el tamaño del prompt, realizar un few-shot learning podría no ser adecuado para tareas complejas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yKe7ztQzmq7",
        "outputId": "f5c5ec25-2c12-4c0d-dc0a-30dc0f86da4d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Nombre]: David Melvin\n",
            "[Puesto]: Consejero Senior\n",
            "[Empresa]: CITIC CLSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeral B\n",
        "\n",
        "Diseñe un prompt que permita generar tweets (máximo 150 caracteres) en base a tres palabras del usuario: empresa, un día de la semana, y un producto. Ej:\n",
        "\n",
        "Tesla\n",
        "Lunes\n",
        "Carro Model S\n",
        "\n",
        "-> Este Lunes Tesla abrio con las acciones en alsa gracias al lanzamiento del nuevo Model S"
      ],
      "metadata": {
        "id": "pl2M7WMY525M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Usar esta celda para entregar numeral B\n",
        "prompt = f\"\"\"\n",
        "[Empresa]: Tesla\n",
        "[Día de la Semana]: Lunes\n",
        "[Producto]: Carro Model S\n",
        "[tweet (máximo 150 caracteres)]: Este Lunes Tesla abrio con las acciones en alsa gracias al lanzamiento del nuevo Model S.\n",
        "###\n",
        "[Empresa]: Bancolombia\n",
        "[Día de la Semana]: Martes\n",
        "[Producto]: CDT\n",
        "[tweet (máximo 150 caracteres)]: Puedes abrir tu CDT Bancolombia Los dias Martes con una tasa 14.70% E.A.\n",
        "###\n",
        "[Empresa]: MercadoLibre\n",
        "[Día de la Semana]: Viernes\n",
        "[Producto]: Carros\n",
        "[tweet (máximo 150 caracteres)]: El proximo Viernes puedes comprar Carros con 50% de descuento.\n",
        "###\n",
        "[Empresa]: Amazon\n",
        "[Día de la Semana]: Sábado\n",
        "[Producto]: Playstation\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "cAZoTMsm6qdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc297994-12d8-442b-a198-46331a81576a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tweet (máximo 150 caracteres)]: Este Sábado aprovecha la oferta de Amazon y consigue tu Playstation con un 20% de descuento. ¡No te lo pierdas! #AmazonOfertas #Playstation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero shot learning\n",
        "\n",
        "Este modelo de lenguage es tan poderoso que para algunas tareas no es necesario especificarle ejemplos, a esto se le llama zero shot y es de hecho la razón por la cual se cree que estos LLMs tienen un entendimiento parcial del mundo, Veamos unos ejemplos."
      ],
      "metadata": {
        "id": "jHPDlrja7H6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\" Increible!,\n",
        "Compré esto para la observación de aves y es un binocular muy bueno.\n",
        "No pesa, es fácil de enfocar y es útil para caminar por el parque o por el bosque.\n",
        "También proporciona un archivo adjunto para el teléfono, por lo que la fotografía de aves se ha convertido en mi nuevo pasatiempo.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "¿Cuál es el sentimiento de la siguiente revisión del producto,\n",
        "que se delimita con triple backticks?\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faR6v6CZ7llN",
        "outputId": "91bdc3e0-c6e7-4f77-dd41-74c1396eb75f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El sentimiento de la revisión del producto es muy positivo y entusiasta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeral C\n",
        "\n",
        "Los zero shot tienen limitaciones. Proponga un review que confunda al modelo de lenguaje y lo haga generar una salida erronea."
      ],
      "metadata": {
        "id": "525z3iN88t7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Usar esta celda para entregar numeral C\n",
        "\n",
        "review = \"\"\" Maravilloso!\n",
        "Tienen que comprarlo!!! Solo 90k. Me toco empeñar la casa para comprarlo.\n",
        "Vale la pena.\n",
        "Increíble experiencia.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "¿Cuál es el sentimiento de la siguiente revisión del producto,\n",
        "que se delimita con triple backticks? se debe tener especial cuidado con el uso de sarcasmo.\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "i5-i9gFA9CBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd07b56-aa9e-44d5-8ffc-3511dcc0c1a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se detecta sarcasmo en la revisión, el sentimiento es positivo y se expresa satisfacción con el producto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeral D\n",
        "\n",
        "Propongan un few shot prompting que permita identificar **las** siguientes emociones: furia/ira, alegría, tristeza, y sorpresa."
      ],
      "metadata": {
        "id": "XBRmJOXl9VsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Usar esta celda para entregar numeral D\n",
        "prompt = f\"\"\"\n",
        "Clasifique el texto en una de 4 categorias: furia, alegría, tristeza, y sorpresa\n",
        "Basese en los siguientes ejemplos:\n",
        "\n",
        "[Texto]: Es increiblemente malo!, no puedo creer que haya comprado esta basura, me tienen que devolver el dinero!!.\n",
        "[Sentimiento]: Furia\n",
        "###\n",
        "[Texto]: Increible!, la mejor compra que he realizado en años!\n",
        "[Sentimiento]: Alegría\n",
        "###\n",
        "[Texto]: Que decepción, despues de esperar 1 mes a su llegada, me di cuenta que el formato de entrada no me servia.\n",
        "[Sentimiento]: Tristeza\n",
        "###\n",
        "[Texto]: Wow, no sabia que tenia incorporado la TDT!, excelente te televisor!\n",
        "[Sentimiento]: Sorpresa\n",
        "###\n",
        "[Texto]: terrible, nada recomendado\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1e_t_Wd2-vBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3bede4-4d85-42e1-abe3-2809e40a5710"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentimiento]: Tristeza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cambios de tonalidad en el texto\n",
        "\n",
        "Con un LLMs podemos cambiar el tono del texto sin perder la semantica original del mismo."
      ],
      "metadata": {
        "id": "R952EjJJ-wW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Reescribir el siguiente texto a un lenguaje formal de negocios:\n",
        "'Como vamos parcero, te escribo para ver si te llego los respuestos del cacharro ese que te vendieron. Yo te los puedo conseguir por menos lucas con un pana de mi papa'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6-Vxzpm_TOl",
        "outputId": "c329c9c1-8a37-4526-a01d-82e351ddc23a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimado/a señor/a,\n",
            "\n",
            "Me dirijo a usted con el fin de confirmar si ha recibido los repuestos correspondientes al producto que adquirió recientemente. Me complace informarle que puedo ofrecerle una alternativa más económica a través de un contacto personal de mi padre.\n",
            "\n",
            "Quedo a la espera de su respuesta.\n",
            "\n",
            "Atentamente,\n",
            "\n",
            "[Su nombre]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los modelos de lenguaje tambien son fenomenales para traducción.\n",
        "\n"
      ],
      "metadata": {
        "id": "UBPygY8bAdpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Reescribir el siguiente texto a un lenguaje formal de negocios, en inglés y japonés:\n",
        "'Como vamos parcero, te escribo para ver si te llego los respuestos del cacharro ese que te vendieron. Yo te los puedo conseguir por menos lucas con un pana de mi papa'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw2o9KwWAq2s",
        "outputId": "0c315759-f0a1-4584-d17d-5dc2916aff9f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: \n",
            "\n",
            "Dear Sir/Madam, \n",
            "\n",
            "I am writing to inquire if you have received the spare parts for the equipment that you purchased. I can acquire them for you at a lower cost through a business contact of my father. \n",
            "\n",
            "Thank you for your attention to this matter. \n",
            "\n",
            "Sincerely, \n",
            "\n",
            "[Your Name] \n",
            "\n",
            "Japanese: \n",
            "\n",
            "尊敬するお客様へ、 \n",
            "\n",
            "このたびはお買い上げいただきありがとうございます。お問い合わせさせていただきたいことがございます。お手元にご注文いただいた機器の部品が届いているかどうかを確認したく、ご連絡を差し上げました。また、私の父親のビジネスコンタクトを通じて、より低価格で部品を手配することができます。 \n",
            "\n",
            "ご検討いただけますようお願い申し上げます。 \n",
            "\n",
            "敬具、 \n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeral E\n",
        "\n",
        "Use una definición de Inteligencia Artificial que encuentre en Internet. Solicite al modelo de lenguaje que lo reescriba en lenguaje formal, informal, regional (paisa, caleño, costeño, etc) y en diferentes lenguajes. Deje ejecutado en el notebook la salida que mas le haya gustado."
      ],
      "metadata": {
        "id": "4X9mwWmXBjMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Usar esta celda para entregar numeral E\n",
        "prompt = f\"\"\"\n",
        "Reescribir el siguiente texto a un lenguaje informal con el argot Chileno extremadamente informal:\n",
        "'La Inteligencia Artificial (IA) es la combinación de algoritmos planteados con el propósito de crear máquinas que presenten las mismas capacidades que el ser humano. Una tecnología que todavía nos resulta lejana y misteriosa, pero que desde hace unos años está presente en nuestro día a día a todas horas.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "tvvp37lyB8-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ab024c-3c61-43ed-d8c3-390629069e8e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La IA es como una mezcla de códigos que hacen que las máquinas se parezcan a nosotros, con toa' la habilidad que tenemos. Es una tecnología que todavía nos pone a pensar y nos deja con cara de what, pero que ya lleva un tiempo presente en todo lo que hacemos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0L7-8D_S5Sc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}