{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYwiEnOhxkoR",
        "outputId": "ee537d08-1b1b-4969-d7be-a2eaf4e0d7fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Library imports\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "import string, unicodedata, re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the file path\n",
        "file_path_creole_law = './/content//ley_wayuu.txt'  # Replace with the path to your text file\n",
        "\n",
        "# Read the content of the file and split it into sentences\n",
        "with open(file_path_creole_law, 'r', encoding='utf-8') as file:\n",
        "    sentences_wayuu = [line.strip() for line in file if line.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sentences_wayuu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the file path\n",
        "file_path_spanish_law = './/content//ley_espanol.txt'  # Replace with the path to your text file\n",
        "\n",
        "# Read the content of the file and split it into sentences\n",
        "with open(file_path_spanish_law, 'r', encoding='utf-8') as file:\n",
        "    sentences_spanish = [line.strip() for line in file if line.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sentences_spanish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wayuu = pd.DataFrame({'español': sentences_spanish, 'wayuu': sentences_wayuu})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wayuu_prepros = text_preprocessing(df_wayuu, 'español', 'wayuu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>español</th>\n",
              "      <th>wayuu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;s&gt; pobreza &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; moju  kat  muli  akat &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; camara de representante &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; shikipu  jana  tuu &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; politico &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; aluuwatawaa &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;s&gt; construir &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; akumaja &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;s&gt; acordado &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; oonowaa amaa &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             español                           wayuu\n",
              "10                  <s> pobreza </s>  <s> moju  kat  muli  akat </s>\n",
              "11  <s> camara de representante </s>     <s> shikipu  jana  tuu </s>\n",
              "12                 <s> politico </s>            <s> aluuwatawaa </s>\n",
              "13                <s> construir </s>                <s> akumaja </s>\n",
              "14                 <s> acordado </s>           <s> oonowaa amaa </s>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_wayuu_prepros[10:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nHWuFbEEx4SK"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus.reader.tagged import word_tokenize\n",
        "def remove_non_ascii_from_text(text):\n",
        "  # Remove non-ASCII characters from a text string\n",
        "  new_text = []\n",
        "  words = word_tokenize(text, language='english')\n",
        "  for word in words:\n",
        "    new_word = unicodedata.normalize('NFKD', str(word)).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    new_text.append(new_word)\n",
        "  new_text = ' '.join(new_text)\n",
        "  return new_text\n",
        "\n",
        "def to_lowercase_from_text(text):\n",
        "  # Convert all characters to lowercase from a text string\n",
        "  new_text = text.lower()\n",
        "  return new_text\n",
        "\n",
        "def remove_punctuation_from_text(text):\n",
        "  # Remove punctuation from a text string\n",
        "  new_text = re.sub(r'[^\\w\\s?!]', '', text)\n",
        "  return new_text\n",
        "\n",
        "def add_tags(text):\n",
        "  return '<s> ' + text + ' </s>'\n",
        "\n",
        "def text_preprocessing(df, column_name_1, column_name_2):\n",
        "  # Apply the preprocessing functions to a specific column in the DataFrame\n",
        "  df[column_name_1] = df[column_name_1].apply(remove_non_ascii_from_text)\n",
        "  df[column_name_1] = df[column_name_1].apply(to_lowercase_from_text)\n",
        "  df[column_name_1] = df[column_name_1].apply(remove_punctuation_from_text)\n",
        "  df[column_name_1] = df[column_name_1].apply(add_tags)\n",
        "  df[column_name_2] = df[column_name_2].apply(remove_non_ascii_from_text)\n",
        "  df[column_name_2] = df[column_name_2].apply(to_lowercase_from_text)\n",
        "  df[column_name_2] = df[column_name_2].apply(remove_punctuation_from_text)\n",
        "  df[column_name_2] = df[column_name_2].apply(add_tags)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lbgxn1qulaYW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory_path = './/content//biblia_espanol//'\n",
        "\n",
        "all_file_text_spanish = []\n",
        "\n",
        "# Function to extract the numerical part of a filename\n",
        "def extract_file_number(filename):\n",
        "    match = re.search(r'\\d+', filename)\n",
        "    if match:\n",
        "        return int(match.group())\n",
        "    return 0\n",
        "\n",
        "# Get a list of files in the directory and sort them by their numerical part\n",
        "files_in_directory = os.listdir(directory_path)\n",
        "files_in_directory = sorted(files_in_directory, key=lambda x: extract_file_number(x))\n",
        "\n",
        "for filename in files_in_directory:\n",
        "    if filename.startswith('biblia_espanol_') and filename.endswith('.txt'):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            start_index = text.find(\"\\n1\")\n",
        "            file_text = text[start_index + len(\"\\n1\"):]\n",
        "            file_text = file_text.replace(\"\\n\", \" \")\n",
        "            file_text = ' '.join(file_text.split())\n",
        "            file_text = re.sub(r'[^\\w\\s]', '', file_text)\n",
        "            file_text = unicodedata.normalize('NFKD', file_text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "            file_text = re.sub(r'(\\d+)', r'.', file_text)\n",
        "            file_text = re.sub(r' (?=\\.)', '', file_text)\n",
        "            file_text = file_text.replace(\"..\", \".\")\n",
        "            file_text = re.sub(r'(\\.)', r'. ', file_text)\n",
        "            file_text = file_text.split('. ')\n",
        "            file_text = [text for text in file_text if text != \"\"]\n",
        "            all_file_text_spanish += file_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mlMvordztisK"
      },
      "outputs": [],
      "source": [
        "directory_path = './/content//biblia_wayuu/'\n",
        "\n",
        "all_file_text_wayuu = []\n",
        "\n",
        "# Function to extract the numerical part of a filename\n",
        "def extract_file_number(filename):\n",
        "    match = re.search(r'\\d+', filename)\n",
        "    if match:\n",
        "        return int(match.group())\n",
        "    return 0\n",
        "\n",
        "# Get a list of files in the directory and sort them by their numerical part\n",
        "files_in_directory = os.listdir(directory_path)\n",
        "files_in_directory = sorted(files_in_directory, key=lambda x: extract_file_number(x))\n",
        "\n",
        "for filename in files_in_directory:\n",
        "    if filename.startswith('biblia_wayuu_') and filename.endswith('.txt'):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            start_index = text.find(\"\\n1\")\n",
        "            file_text = text[start_index + len(\"\\n1\"):]\n",
        "            file_text = file_text.replace(\"\\n\", \" \")\n",
        "            file_text = ' '.join(file_text.split())\n",
        "            file_text = re.sub(r'[^\\w\\s]', '', file_text)\n",
        "            file_text = unicodedata.normalize('NFKD', file_text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "            file_text = re.sub(r'(\\d+)', r'.', file_text)\n",
        "            file_text = re.sub(r' (?=\\.)', '', file_text)\n",
        "            file_text = file_text.replace(\"..\", \".\")\n",
        "            file_text = re.sub(r'(\\.)', r'. ', file_text)\n",
        "            file_text = file_text.split('. ')\n",
        "            file_text = [text for text in file_text if text != \"\"]\n",
        "            all_file_text_wayuu += file_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifb4nxiVv6Wx",
        "outputId": "b613085e-afc1-4d7d-c195-63a9c977c8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1292, 1292)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_file_text_wayuu), len(all_file_text_spanish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d5KsNDRR0lvQ"
      },
      "outputs": [],
      "source": [
        "bible_df = pd.DataFrame({'español': all_file_text_spanish, 'wayuu': all_file_text_wayuu})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "U1VNZUH21383",
        "outputId": "031a428b-8fce-46aa-d91c-38a29878f515"
      },
      "outputs": [],
      "source": [
        "ls_sp = []\n",
        "ls_wa = []\n",
        "for ind in range(len(bible_df[\"español\"])):\n",
        "    l = len(bible_df[\"español\"][ind])\n",
        "    ls_sp.append(l)\n",
        "    l = len(bible_df[\"wayuu\"][ind])\n",
        "    ls_wa.append(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "iii = np.argmax(ls_sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Asi que le enviaron algunos de sus propios seguidores junto con otros que pertenecian al partido de Herodes para que le dijeran  Maestro sabemos que tu eres sincero y que ensenas con toda verdad a vivir como Dios quiere no te preocupa el que diran ni juzgas a la gente por las apariencias'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bible_df[\"español\"][iii]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Najutakalaka na fariseokana wane na nekirajuinkana nunainmuin Jesus ooulaka wane numaajanakana Herodes chi sulaulashikai mma sunain namuin numuin Jesus Ekirajuikalee watujaa aauchi pia sunain shiimuin tu pumakat sunain ekirajaa tu nuluwataakat anain Maleiwa je sunain matujuin pia kachekalaa suutku wayuu'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bible_df[\"wayuu\"][iii]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZChAsOSM2LLJ"
      },
      "outputs": [],
      "source": [
        "bible_df_prepros = text_preprocessing(bible_df, 'español', 'wayuu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PatYwCSq2TCp",
        "outputId": "a7d83a7c-ae7c-4eb3-e5e2-402122334050"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>español</th>\n",
              "      <th>wayuu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; cuando ya los sabios se habian ido un ange...</td>\n",
              "      <td>&lt;s&gt; shiasa suchikijee nounapa na wayuu wuinpuj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; jose se levanto tomo al nino y a su madre ...</td>\n",
              "      <td>&lt;s&gt; nuchijiraakalaka jose sunain nujuittuin nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; donde estuvieron hasta que murio herodes e...</td>\n",
              "      <td>&lt;s&gt; eeinjanale kepiain naya waneereeya ouktapa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; al darse cuenta herodes de que aquellos sa...</td>\n",
              "      <td>&lt;s&gt; je nutujaapa saau herodes sunain nemeerain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; asi se cumplio lo escrito por el profeta j...</td>\n",
              "      <td>&lt;s&gt; alatusu tuu supula keraainjatuin tu nunuik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1287</th>\n",
              "      <td>&lt;s&gt; y aunque es verdad que dios no ha tomado e...</td>\n",
              "      <td>&lt;s&gt; nnojotsu kasalajanapuuin sumuin wayuu nutu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288</th>\n",
              "      <td>&lt;s&gt; y ya tiene fijado el dia en que ha de juzg...</td>\n",
              "      <td>&lt;s&gt; suka jamuin maleiwakai niitaain wane kai n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>&lt;s&gt; cuando oyeron hablar de resurreccion de mu...</td>\n",
              "      <td>&lt;s&gt; je nouluku na eejanakana naapapa suchiki t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>&lt;s&gt; asi que pablo abandono la reunion &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; nuunakalaka pablo namaanajee &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1291</th>\n",
              "      <td>&lt;s&gt; sin embargo hubo quienes se unieron a el y...</td>\n",
              "      <td>&lt;s&gt; nayasaa waneeinnua acheinraashii numaa ott...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1292 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                español  \\\n",
              "0     <s> cuando ya los sabios se habian ido un ange...   \n",
              "1     <s> jose se levanto tomo al nino y a su madre ...   \n",
              "2     <s> donde estuvieron hasta que murio herodes e...   \n",
              "3     <s> al darse cuenta herodes de que aquellos sa...   \n",
              "4     <s> asi se cumplio lo escrito por el profeta j...   \n",
              "...                                                 ...   \n",
              "1287  <s> y aunque es verdad que dios no ha tomado e...   \n",
              "1288  <s> y ya tiene fijado el dia en que ha de juzg...   \n",
              "1289  <s> cuando oyeron hablar de resurreccion de mu...   \n",
              "1290         <s> asi que pablo abandono la reunion </s>   \n",
              "1291  <s> sin embargo hubo quienes se unieron a el y...   \n",
              "\n",
              "                                                  wayuu  \n",
              "0     <s> shiasa suchikijee nounapa na wayuu wuinpuj...  \n",
              "1     <s> nuchijiraakalaka jose sunain nujuittuin nu...  \n",
              "2     <s> eeinjanale kepiain naya waneereeya ouktapa...  \n",
              "3     <s> je nutujaapa saau herodes sunain nemeerain...  \n",
              "4     <s> alatusu tuu supula keraainjatuin tu nunuik...  \n",
              "...                                                 ...  \n",
              "1287  <s> nnojotsu kasalajanapuuin sumuin wayuu nutu...  \n",
              "1288  <s> suka jamuin maleiwakai niitaain wane kai n...  \n",
              "1289  <s> je nouluku na eejanakana naapapa suchiki t...  \n",
              "1290              <s> nuunakalaka pablo namaanajee </s>  \n",
              "1291  <s> nayasaa waneeinnua acheinraashii numaa ott...  \n",
              "\n",
              "[1292 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bible_df_prepros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OeU61aQD2Uro"
      },
      "outputs": [],
      "source": [
        "wayuu = pd.concat([df_wayuu_prepros, bible_df_prepros], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ghszXhlU3BPw",
        "outputId": "ba518d96-89ca-45f5-f36c-6d3f083749b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>español</th>\n",
              "      <th>wayuu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; principio &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; sutia sukuipa &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; acuerdo final para la terminacion del conf...</td>\n",
              "      <td>&lt;s&gt; koutushi naa wayukana napushuale supula ei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; salvaguardas y garantia &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; akuipa aka kojutunjatuu wakuipa &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; reforma rural integral &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; awanajawa sukuipaa woumain &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; planes de vida &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; akumaja supula anan akuipaa wepiapaa &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>&lt;s&gt; y aunque es verdad que dios no ha tomado e...</td>\n",
              "      <td>&lt;s&gt; nnojotsu kasalajanapuuin sumuin wayuu nutu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1330</th>\n",
              "      <td>&lt;s&gt; y ya tiene fijado el dia en que ha de juzg...</td>\n",
              "      <td>&lt;s&gt; suka jamuin maleiwakai niitaain wane kai n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1331</th>\n",
              "      <td>&lt;s&gt; cuando oyeron hablar de resurreccion de mu...</td>\n",
              "      <td>&lt;s&gt; je nouluku na eejanakana naapapa suchiki t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>&lt;s&gt; asi que pablo abandono la reunion &lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt; nuunakalaka pablo namaanajee &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>&lt;s&gt; sin embargo hubo quienes se unieron a el y...</td>\n",
              "      <td>&lt;s&gt; nayasaa waneeinnua acheinraashii numaa ott...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1334 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                español  \\\n",
              "0                                    <s> principio </s>   \n",
              "1     <s> acuerdo final para la terminacion del conf...   \n",
              "2                      <s> salvaguardas y garantia </s>   \n",
              "3                       <s> reforma rural integral </s>   \n",
              "4                               <s> planes de vida </s>   \n",
              "...                                                 ...   \n",
              "1329  <s> y aunque es verdad que dios no ha tomado e...   \n",
              "1330  <s> y ya tiene fijado el dia en que ha de juzg...   \n",
              "1331  <s> cuando oyeron hablar de resurreccion de mu...   \n",
              "1332         <s> asi que pablo abandono la reunion </s>   \n",
              "1333  <s> sin embargo hubo quienes se unieron a el y...   \n",
              "\n",
              "                                                  wayuu  \n",
              "0                                <s> sutia sukuipa </s>  \n",
              "1     <s> koutushi naa wayukana napushuale supula ei...  \n",
              "2              <s> akuipa aka kojutunjatuu wakuipa </s>  \n",
              "3                   <s> awanajawa sukuipaa woumain </s>  \n",
              "4         <s> akumaja supula anan akuipaa wepiapaa </s>  \n",
              "...                                                 ...  \n",
              "1329  <s> nnojotsu kasalajanapuuin sumuin wayuu nutu...  \n",
              "1330  <s> suka jamuin maleiwakai niitaain wane kai n...  \n",
              "1331  <s> je nouluku na eejanakana naapapa suchiki t...  \n",
              "1332              <s> nuunakalaka pablo namaanajee </s>  \n",
              "1333  <s> nayasaa waneeinnua acheinraashii numaa ott...  \n",
              "\n",
              "[1334 rows x 2 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wayuu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "hyrtxxeo3IIp"
      },
      "outputs": [],
      "source": [
        "wayuu.to_excel('wayuu_dataset.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRC33YY93ley",
        "outputId": "5ad01d96-ae6e-4a82-9ef5-c0d723cab7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique words: 3877\n"
          ]
        }
      ],
      "source": [
        "# Function to count unique words in a text column\n",
        "def count_unique_words(text_column):\n",
        "    # Tokenize the text into words\n",
        "    words = text_column.str.split().explode()\n",
        "\n",
        "    # Count unique words using a set\n",
        "    unique_words = set(words)\n",
        "\n",
        "    return len(unique_words)\n",
        "\n",
        "# Apply the function to your DataFrame's text column\n",
        "unique_word_count = count_unique_words(wayuu['español'])\n",
        "\n",
        "print(f\"Number of unique words: {unique_word_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
