{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import tarfile\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe descaragr el archivo \"Datasets.zip\" en el mismo directorio de el notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "compressed_file = \"Datasets.zip\"\n",
    "with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "    folder_name = os.path.splitext(compressed_file)[0]  # Remove the \".zip\" extension\n",
    "    target_folder = os.path.join(folder_name)\n",
    "    \n",
    "    if not os.path.exists(target_folder):\n",
    "        # Create the folder within the target directory\n",
    "        os.mkdir(target_folder)\n",
    "\n",
    "    \n",
    "        # Extract all files to the target folder\n",
    "        zip_ref.extractall(target_folder)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "compressed_file = \"Datasets\\\\20news-18828.tar.gz\"\n",
    "folder_name = os.path.splitext(os.path.splitext(compressed_file)[0])[0]  # Remove the \".tar.gz\" extension\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "# Extract all files from the TAR.GZ archive to the target folder without creating an additional subfolder\n",
    "with tarfile.open(compressed_file, 'r:gz') as tar_ref:\n",
    "    members = tar_ref.getmembers()\n",
    "    tar_ref.extractall(path=folder_name, members=members)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación train-test-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the 20N dataset folder\n",
    "dataset_folder = \"Datasets/20news-18828/20news-18828\"\n",
    "\n",
    "# Load and preprocess the text data\n",
    "data = []\n",
    "labels = []\n",
    "for category in os.listdir(dataset_folder):\n",
    "    category_path = os.path.join(dataset_folder, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "                content = file.read()\n",
    "                data.append(content)\n",
    "                labels.append(category)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=13)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.33, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
       "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
       "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
       "       'sci.electronics', 'sci.med', 'sci.space',\n",
       "       'soc.religion.christian', 'talk.politics.guns',\n",
       "       'talk.politics.mideast', 'talk.politics.misc',\n",
       "       'talk.religion.misc'], dtype='<U24')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de Representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorizers for \"tf\" and \"tfidf\" representations\n",
    "tf_vectorizer = CountVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the vectorizers on training data\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform validation and test data\n",
    "X_val_tf = tf_vectorizer.transform(X_val)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tf = tf_vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento & Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train Naive Bayes (MultinomialNB) and Logistic Regression (LogisticRegression) classifiers\n",
    "nb_classifier = MultinomialNB()\n",
    "lr_classifier = LogisticRegression(max_iter=500)\n",
    "\n",
    "nb_classifier.fit(X_train_tf, y_train)\n",
    "lr_classifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (tf representation):\n",
      "Naive Bayes Accuracy: 0.811046511627907\n",
      "Logistic Regression Accuracy: 0.8535940803382663\n",
      "\n",
      "Test Results (tf representation):\n",
      "Naive Bayes Accuracy: 0.8016085790884718\n",
      "Logistic Regression Accuracy: 0.8605898123324397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifiers on validation data\n",
    "val_preds_nb = nb_classifier.predict(X_val_tf)\n",
    "val_preds_lr = lr_classifier.predict(X_val_tf)\n",
    "\n",
    "print(\"Validation Results (tf representation):\")\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, val_preds_nb))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, val_preds_lr))\n",
    "\n",
    "# Evaluate classifiers on test data\n",
    "test_preds_nb = nb_classifier.predict(X_test_tf)\n",
    "test_preds_lr = lr_classifier.predict(X_test_tf)\n",
    "\n",
    "print(\"\\nTest Results (tf representation):\")\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, test_preds_nb))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, test_preds_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train Naive Bayes (MultinomialNB) and Logistic Regression (LogisticRegression) classifiers\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "lr_classifier_tfidf = LogisticRegression(max_iter=500)\n",
    "\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "lr_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results (tfidf representation):\n",
      "Naive Bayes Accuracy: 0.846723044397463\n",
      "Logistic Regression Accuracy: 0.8736786469344608\n",
      "\n",
      "Test Results (tfidf representation):\n",
      "Naive Bayes Accuracy: 0.8557640750670241\n",
      "Logistic Regression Accuracy: 0.8729222520107238\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifiers on validation data\n",
    "val_preds_nb = nb_classifier.predict(X_val_tfidf)\n",
    "val_preds_lr = lr_classifier.predict(X_val_tfidf)\n",
    "\n",
    "print(\"Validation Results (tfidf representation):\")\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, val_preds_nb))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, val_preds_lr))\n",
    "\n",
    "# Evaluate classifiers on test data\n",
    "test_preds_nb = nb_classifier.predict(X_test_tfidf)\n",
    "test_preds_lr = lr_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nTest Results (tfidf representation):\")\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, test_preds_nb))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, test_preds_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada es una técnica utilizada para evaluar el que tan bien generaliza un modelo de aprendizaje automático. Es particularmente útil cuando se dispone de una cantidad limitada de datos. La estrategia consiste en dividir el conjunto de datos en múltiples subconjuntos (folds), entrenar el modelo en algunos de estos subconjuntos y probarlo en los subconjuntos restantes. Este proceso se repite varias veces y las métricas de rendimiento se promedian en estas iteraciones. Los principales objetivos de la validación cruzada son los siguientes:\n",
    "\n",
    "- Evaluar el Rendimiento del Modelo: La validación cruzada ayuda a estimar qué tan bien un modelo generalizará a datos no vistos, proporcionando una evaluación más robusta en comparación con una sola división de entrenamiento y prueba.\n",
    "\n",
    "- Ajuste de Hiperparámetros: Puede ayudar en la búsqueda de hiperparámetros evaluando diferentes combinaciones de hiperparámetros en múltiples folds, lo que ayuda a seleccionar el mejor conjunto de hiperparámetros.\n",
    "\n",
    "- Evitar el Sobreajuste: La validación cruzada ayuda a detectar el sobreajuste. Si un modelo tiene un buen desempeño en los datos de entrenamiento pero un mal desempeño en los datos de validación o prueba, es posible que esté sobreajustando los datos de entrenamiento.\n",
    "\n",
    "- Optimizar la Selección del Modelo: Ayuda a comparar diferentes modelos y seleccionar aquel que tenga el mejor rendimiento en promedio entre los pliegues.\n",
    "\n",
    "Así es cómo se puede comparar Naive Bayes (NB) y Regresión Logística (LR) utilizando una validación cruzada de K pliegues con conjuntos de entrenamiento y validación, y realizar la búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 10\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=13)\n",
    "# Initialize classifiers\n",
    "nb_classifier = MultinomialNB()\n",
    "lr_classifier = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Combine training and validation sets\n",
    "X_combined = vstack((X_train_tfidf, X_val_tfidf))\n",
    "y_combined = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for LR grid search (e.g., learning rate)\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1.0],  # Regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Solver algorithms\n",
    "}\n",
    "\n",
    "# Initialize LR classifier for grid search\n",
    "lr_grid_search = GridSearchCV(estimator=lr_classifier, param_grid=lr_params, cv=kf, scoring='f1_macro')\n",
    "lr_grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "# Get the best LR model after hyperparameter tuning\n",
    "best_lr_classifier = lr_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report (Combined Training+Validation Set):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.95      0.93      0.94       718\n",
      "           comp.graphics       0.88      0.91      0.89       875\n",
      " comp.os.ms-windows.misc       0.89      0.90      0.89       874\n",
      "comp.sys.ibm.pc.hardware       0.88      0.90      0.89       898\n",
      "   comp.sys.mac.hardware       0.95      0.92      0.94       850\n",
      "          comp.windows.x       0.94      0.92      0.93       880\n",
      "            misc.forsale       0.91      0.91      0.91       870\n",
      "               rec.autos       0.94      0.96      0.95       887\n",
      "         rec.motorcycles       0.98      0.97      0.98       905\n",
      "      rec.sport.baseball       0.98      0.98      0.98       897\n",
      "        rec.sport.hockey       0.99      0.99      0.99       912\n",
      "               sci.crypt       0.99      0.97      0.98       896\n",
      "         sci.electronics       0.91      0.93      0.92       885\n",
      "                 sci.med       0.97      0.97      0.97       899\n",
      "               sci.space       0.98      0.98      0.98       885\n",
      "  soc.religion.christian       0.94      0.98      0.96       884\n",
      "      talk.politics.guns       0.94      0.97      0.95       819\n",
      "   talk.politics.mideast       0.99      0.99      0.99       868\n",
      "      talk.politics.misc       0.97      0.92      0.94       685\n",
      "      talk.religion.misc       0.95      0.85      0.90       576\n",
      "\n",
      "                accuracy                           0.94     16963\n",
      "               macro avg       0.95      0.94      0.94     16963\n",
      "            weighted avg       0.95      0.94      0.94     16963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report precision, recall, and F1 scores for the best Logistic Regression model\n",
    "lr_preds = best_lr_classifier.predict(X_combined)\n",
    "print(\"Logistic Regression Classification Report (Combined Training+Validation Set):\")\n",
    "print(classification_report(y_combined, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search for Naive Bayes (alpha parameter)\n",
    "nb_param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "nb_grid_search = GridSearchCV(nb_classifier, nb_param_grid, cv=kf, scoring='f1_macro')\n",
    "nb_grid_search.fit(X_combined, y_combined)\n",
    "best_nb_classifier = nb_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report (Training Set + Validation Set):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.88      0.87       718\n",
      "           comp.graphics       0.73      0.81      0.77       875\n",
      " comp.os.ms-windows.misc       0.78      0.78      0.78       874\n",
      "comp.sys.ibm.pc.hardware       0.75      0.79      0.77       898\n",
      "   comp.sys.mac.hardware       0.86      0.84      0.85       850\n",
      "          comp.windows.x       0.85      0.85      0.85       880\n",
      "            misc.forsale       0.83      0.83      0.83       870\n",
      "               rec.autos       0.89      0.89      0.89       887\n",
      "         rec.motorcycles       0.92      0.93      0.93       905\n",
      "      rec.sport.baseball       0.96      0.94      0.95       897\n",
      "        rec.sport.hockey       0.96      0.97      0.97       912\n",
      "               sci.crypt       0.96      0.93      0.95       896\n",
      "         sci.electronics       0.82      0.80      0.81       885\n",
      "                 sci.med       0.93      0.91      0.92       899\n",
      "               sci.space       0.93      0.93      0.93       885\n",
      "  soc.religion.christian       0.85      0.93      0.89       884\n",
      "      talk.politics.guns       0.83      0.93      0.88       819\n",
      "   talk.politics.mideast       0.95      0.95      0.95       868\n",
      "      talk.politics.misc       0.88      0.79      0.83       685\n",
      "      talk.religion.misc       0.88      0.58      0.70       576\n",
      "\n",
      "                accuracy                           0.87     16963\n",
      "               macro avg       0.87      0.86      0.87     16963\n",
      "            weighted avg       0.87      0.87      0.87     16963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation with the best Naive Bayes classifier\n",
    "nb_cv_preds = cross_val_predict(best_nb_classifier, X_combined, y_combined, cv=kf)\n",
    "\n",
    "# Report precision, recall, and F1 scores for Naive Bayes\n",
    "print(\"Naive Bayes Classification Report (Training Set + Validation Set):\")\n",
    "print(classification_report(y_combined, nb_cv_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR supera NB en términos de precisión, macro-average F1-score, y weighted-average F1-score en el set de entrenamiento y validación. \n",
    "esto indica que, en promedio, LR es mejor clasificando documentos en sus respectivas categorías"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
