{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import tarfile\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarnings from scikit-learn\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "compressed_file = \"Datasets.zip\"\n",
    "with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "    folder_name = os.path.splitext(compressed_file)[0]  # Remove the \".zip\" extension\n",
    "    target_folder = os.path.join(folder_name)\n",
    "    \n",
    "    if not os.path.exists(target_folder):\n",
    "        # Create the folder within the target directory\n",
    "        os.mkdir(target_folder)\n",
    "\n",
    "        # Extract all files to the target folder\n",
    "        zip_ref.extractall(target_folder)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "compressed_file = \"Datasets\\\\20news-18828.tar.gz\"\n",
    "folder_name = os.path.splitext(os.path.splitext(compressed_file)[0])[0]  # Remove the \".tar.gz\" extension\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "# Extract all files from the TAR.GZ archive to the target folder without creating an additional subfolder\n",
    "with tarfile.open(compressed_file, 'r:gz') as tar_ref:\n",
    "    members = tar_ref.getmembers()\n",
    "    tar_ref.extractall(path=folder_name, members=members)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada\n"
     ]
    }
   ],
   "source": [
    "compressed_file = \"Datasets\\\\Multi Domain Sentiment\\\\processed_acl.tar.gz\"\n",
    "folder_name = os.path.splitext(os.path.splitext(compressed_file)[0])[0]  # Remove the \".tar.gz\" extension\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "# Extract all files from the TAR.GZ archive to the target folder without creating an additional subfolder\n",
    "with tarfile.open(compressed_file, 'r:gz') as tar_ref:\n",
    "    members = tar_ref.getmembers()\n",
    "    tar_ref.extractall(path=folder_name, members=members)\n",
    "\n",
    "print(\"Extracción completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos y preparación de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset and categories\n",
    "data_path = \"Datasets\\\\Multi Domain Sentiment\\\\processed_acl\\\\processed_acl\"\n",
    "categories = [\"books\", \"dvd\", \"electronics\", \"kitchen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract reviews and their labels with a specified limit\n",
    "def extract_reviews_and_labels(category, sentiment, max_reviews=None):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    folder_path = os.path.join(data_path, category)\n",
    "    filename = f\"{sentiment}.review\"\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            # se tiene en cuenta la entrada, se pone en formato de texto limpio, repitiendo las palabras cuando en la estructura \"str:num\" num!=1\n",
    "            line_clean = re.sub(r'(\\w+):(\\d+)', lambda x: (x.group(1) + ' ') * (int(x.group(2)) - 1) + x.group(1), line)\n",
    "            line_clean = line_clean.strip()\n",
    "            if line_clean:\n",
    "                # Split the line into features and label parts\n",
    "                parts = line_clean.split(\"#label#:\")\n",
    "                if len(parts) == 2:\n",
    "                    review = parts[0].strip()\n",
    "                    label = parts[1].strip()\n",
    "                    reviews.append(review)\n",
    "                    labels.append(label)\n",
    "                    if max_reviews is not None and len(reviews) >= max_reviews:\n",
    "                        break  # Stop extracting if the maximum number of reviews is reached\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature representation strategies\n",
    "vectorizers = {\n",
    "    \"tf\": CountVectorizer(), \n",
    "    \"tfidf\": TfidfVectorizer(),\n",
    "}\n",
    "\n",
    "# Initialize results dataframe\n",
    "results_df = pd.DataFrame(\n",
    "    columns=[\"Category\", \"Algorithm\", \"Representation\", \"Precision\", \"Recall\", \"F1\", \"Accuracy\"]\n",
    ")\n",
    "\n",
    "# Filter out all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Category: books, Algorithm: NB, Representation: tf\n",
      "_________________________\n",
      "Processing Category: books, Algorithm: NB, Representation: tfidf\n",
      "_________________________\n",
      "Processing Category: books, Algorithm: LR, Representation: tf\n",
      "Category: books\n",
      "Top 10 features: ['enjoyed', 'everything', 'a_must', 'wonderful', 'must', 'the_best', 'loved', 'easy', 'great', 'excellent']\n",
      "\n",
      "_________________________\n",
      "Processing Category: books, Algorithm: LR, Representation: tfidf\n",
      "Category: books\n",
      "Top 10 features: ['a_great', 'love', 'the_best', 'best', 'must', 'my', 'you', 'easy', 'excellent', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: dvd, Algorithm: NB, Representation: tf\n",
      "_________________________\n",
      "Processing Category: dvd, Algorithm: NB, Representation: tfidf\n",
      "_________________________\n",
      "Processing Category: dvd, Algorithm: LR, Representation: tf\n",
      "Category: dvd\n",
      "Top 10 features: ['season', 'well', 'still', 'wonderful', 'enjoy', 'loved', 'love', 'best', 'excellent', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: dvd, Algorithm: LR, Representation: tfidf\n",
      "Category: dvd\n",
      "Top 10 features: ['wonderful', 'the_best', 'a_great', 'well', 'season', 'his', 'excellent', 'love', 'best', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: electronics, Algorithm: NB, Representation: tf\n",
      "_________________________\n",
      "Processing Category: electronics, Algorithm: NB, Representation: tfidf\n",
      "_________________________\n",
      "Processing Category: electronics, Algorithm: LR, Representation: tf\n",
      "Category: electronics\n",
      "Top 10 features: ['the_best', 'highly', 'works', 'good', 'fast', 'best', 'price', 'perfect', 'excellent', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: electronics, Algorithm: LR, Representation: tfidf\n",
      "Category: electronics\n",
      "Top 10 features: ['the_best', 'the_price', 'easy', 'best', 'works', 'perfect', 'good', 'excellent', 'price', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: kitchen, Algorithm: NB, Representation: tf\n",
      "_________________________\n",
      "Processing Category: kitchen, Algorithm: NB, Representation: tfidf\n",
      "_________________________\n",
      "Processing Category: kitchen, Algorithm: LR, Representation: tf\n",
      "Category: kitchen\n",
      "Top 10 features: ['nice', 'well', 'easy_to', 'works', 'perfect', 'excellent', 'best', 'love', 'easy', 'great']\n",
      "\n",
      "_________________________\n",
      "Processing Category: kitchen, Algorithm: LR, Representation: tfidf\n",
      "Category: kitchen\n",
      "Top 10 features: ['well', 'i_love', 'perfect', 'excellent', 'best', 've', 'easy_to', 'love', 'easy', 'great']\n",
      "\n",
      "_________________________\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    positive_reviews, positive_labels = extract_reviews_and_labels(category, \"positive\", max_reviews=None)\n",
    "    negative_reviews, negative_labels = extract_reviews_and_labels(category, \"negative\", max_reviews=None)\n",
    "    X_test, y_test = extract_reviews_and_labels(category, \"unlabeled\", max_reviews=None)\n",
    "    X_train = positive_reviews + negative_reviews\n",
    "    y_train = positive_labels + negative_labels\n",
    "\n",
    "    # # Split the data into train and validation sets\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Perform sentiment analysis for each category, algorithm, and feature representation\n",
    "\n",
    "    for algorithm in [\"NB\", \"LR\"]:\n",
    "        for representation, vectorizer in vectorizers.items():\n",
    "            print(f\"Processing Category: {category}, Algorithm: {algorithm}, Representation: {representation}\")\n",
    "            # Initialize the vectorizer\n",
    "            X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "            X_test_vectorized = vectorizer.transform(X_test)\n",
    "            \n",
    "            # Train the classifier\n",
    "            if algorithm == \"NB\":\n",
    "                classifier = MultinomialNB()\n",
    "            elif algorithm == \"LR\":\n",
    "                classifier = LogisticRegression(max_iter=500, random_state=13)  #se reduce numero maximo de iteraciones pq se demora muchísimo\n",
    "                \n",
    "            classifier.fit(X_train_vectorized, y_train)\n",
    "            \n",
    "            # Predict sentiment\n",
    "            y_pred = classifier.predict(X_test_vectorized)\n",
    "            \n",
    "            # Calculate evaluation metrics\n",
    "            precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "            recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "            f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Store results in the dataframe\n",
    "            results_df = results_df.append(\n",
    "                {\n",
    "                    \"Category\": category,\n",
    "                    \"Algorithm\": algorithm,\n",
    "                    \"Representation\": representation,\n",
    "                    \"Precision\": precision,\n",
    "                    \"Recall\": recall,\n",
    "                    \"F1\": f1,\n",
    "                    \"Accuracy\": accuracy,\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            if algorithm=='NB':\n",
    "                print('_________________________')\n",
    "                continue\n",
    "            # Get the top N features (words) for each class (positive and negative)\n",
    "            feature_names = vectorizer.get_feature_names()\n",
    "            top_n = 10  # Adjust the number of top features to display\n",
    "\n",
    "            coef = classifier.coef_[0]  # For binary classification, there's only one set of coefficients\n",
    "            top_features_indices = np.argsort(coef)[-top_n:]\n",
    "            top_features = [feature_names[i] for i in top_features_indices]\n",
    "            print(f\"Category: {category}\")\n",
    "            print(f\"Top {top_n} features: {top_features}\")\n",
    "            print()\n",
    "\n",
    "            print('_________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "       Category Algorithm Representation  Precision    Recall        F1  \\\n",
      "0         books        NB             tf   0.834947  0.826652  0.825808   \n",
      "1         books        NB          tfidf   0.839174  0.823964  0.822292   \n",
      "2         books        LR             tf   0.824635  0.824636  0.824635   \n",
      "3         books        LR          tfidf   0.833220  0.832027  0.831960   \n",
      "4           dvd        NB             tf   0.820063  0.819855  0.819847   \n",
      "5           dvd        NB          tfidf   0.848160  0.846068  0.845892   \n",
      "6           dvd        LR             tf   0.832617  0.832404  0.832355   \n",
      "7           dvd        LR          tfidf   0.845131  0.844953  0.844914   \n",
      "8   electronics        NB             tf   0.854781  0.854779  0.854777   \n",
      "9   electronics        NB          tfidf   0.866608  0.865517  0.865441   \n",
      "10  electronics        LR             tf   0.858618  0.858476  0.858451   \n",
      "11  electronics        LR          tfidf   0.859836  0.859708  0.859685   \n",
      "12      kitchen        NB             tf   0.877945  0.877881  0.877869   \n",
      "13      kitchen        NB          tfidf   0.880580  0.880404  0.880380   \n",
      "14      kitchen        LR             tf   0.881959  0.881918  0.881910   \n",
      "15      kitchen        LR          tfidf   0.868941  0.868797  0.868775   \n",
      "\n",
      "    Accuracy  \n",
      "0   0.826652  \n",
      "1   0.823964  \n",
      "2   0.824636  \n",
      "3   0.832027  \n",
      "4   0.819855  \n",
      "5   0.846068  \n",
      "6   0.832404  \n",
      "7   0.844953  \n",
      "8   0.854779  \n",
      "9   0.865517  \n",
      "10  0.858476  \n",
      "11  0.859708  \n",
      "12  0.877881  \n",
      "13  0.880404  \n",
      "14  0.881918  \n",
      "15  0.868797  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories with the lowest F1 scores:\n",
      "   Algorithm Representation     Category        F1\n",
      "4         NB             tf          dvd  0.819847\n",
      "1         NB          tfidf        books  0.822292\n",
      "2         LR             tf        books  0.824635\n",
      "0         NB             tf        books  0.825808\n",
      "3         LR          tfidf        books  0.831960\n",
      "6         LR             tf          dvd  0.832355\n",
      "7         LR          tfidf          dvd  0.844914\n",
      "5         NB          tfidf          dvd  0.845892\n",
      "8         NB             tf  electronics  0.854777\n",
      "10        LR             tf  electronics  0.858451\n",
      "11        LR          tfidf  electronics  0.859685\n",
      "9         NB          tfidf  electronics  0.865441\n",
      "15        LR          tfidf      kitchen  0.868775\n",
      "12        NB             tf      kitchen  0.877869\n",
      "13        NB          tfidf      kitchen  0.880380\n",
      "14        LR             tf      kitchen  0.881910\n"
     ]
    }
   ],
   "source": [
    "# Sort the results_df by 'F1' column in ascending order\n",
    "sorted_results_df = results_df.sort_values(by='F1')\n",
    "\n",
    "# Get the rows with the lowest F1 scores\n",
    "lowest_f1_categories = sorted_results_df[sorted_results_df['F1'] == sorted_results_df['F1']]\n",
    "\n",
    "# Print the categories with the lowest F1 scores\n",
    "print(\"Categories with the lowest F1 scores:\")\n",
    "print(lowest_f1_categories[[\"Algorithm\", \"Representation\", 'Category', 'F1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun la métrica F1, lasd clases más dificiles de clasificar son dvd y books, debido a que independientemente de la representación o el algoritmo de clasificación, el desempeño es menor comparado con las clases electronics y kitchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB, Representation: tf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['negative', 'positive']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USUARIO\\Desktop\\tmp\\2023-2\\Precesamiento de Lenguaje Natural\\NLP\\Tarea_3\\sentiment_analysis.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/tmp/2023-2/Precesamiento%20de%20Lenguaje%20Natural/NLP/Tarea_3/sentiment_analysis.ipynb#X35sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m y_pred \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test_vectorized)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/tmp/2023-2/Precesamiento%20de%20Lenguaje%20Natural/NLP/Tarea_3/sentiment_analysis.ipynb#X35sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Calculate evaluation metrics\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/tmp/2023-2/Precesamiento%20de%20Lenguaje%20Natural/NLP/Tarea_3/sentiment_analysis.ipynb#X35sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \u001b[39m# Assuming binary classification\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/tmp/2023-2/Precesamiento%20de%20Lenguaje%20Natural/NLP/Tarea_3/sentiment_analysis.ipynb#X35sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m recall \u001b[39m=\u001b[39m recall_score(y_test, y_pred, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Desktop/tmp/2023-2/Precesamiento%20de%20Lenguaje%20Natural/NLP/Tarea_3/sentiment_analysis.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_test, y_pred, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1776\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[0;32m   1648\u001b[0m     y_true,\n\u001b[0;32m   1649\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1655\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1656\u001b[0m ):\n\u001b[0;32m   1657\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m \n\u001b[0;32m   1659\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1776\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1777\u001b[0m         y_true,\n\u001b[0;32m   1778\u001b[0m         y_pred,\n\u001b[0;32m   1779\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1780\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1781\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1782\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1783\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1784\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1785\u001b[0m     )\n\u001b[0;32m   1786\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1563\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1565\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\anteia\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1372\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[39mif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m present_labels:\n\u001b[0;32m   1371\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(present_labels) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1372\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1373\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpos_label=\u001b[39m\u001b[39m{\u001b[39;00mpos_label\u001b[39m}\u001b[39;00m\u001b[39m is not a valid label. It \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshould be one of \u001b[39m\u001b[39m{\u001b[39;00mpresent_labels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m             )\n\u001b[0;32m   1376\u001b[0m     labels \u001b[39m=\u001b[39m [pos_label]\n\u001b[0;32m   1377\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label. It should be one of ['negative', 'positive']"
     ]
    }
   ],
   "source": [
    "# Combine data from all categories\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for category in categories:\n",
    "    positive_reviews, positive_labels = extract_reviews_and_labels(category, \"positive\", max_reviews=None)\n",
    "    negative_reviews, negative_labels = extract_reviews_and_labels(category, \"negative\", max_reviews=None)\n",
    "    X_train += positive_reviews + negative_reviews\n",
    "    y_train += positive_labels + negative_labels\n",
    "\n",
    "    # Load the test data\n",
    "    X_test_cat, y_test_cat = extract_reviews_and_labels(category, \"unlabeled\", max_reviews=None)\n",
    "    X_test += X_test_cat\n",
    "    y_test += y_test_cat\n",
    "\n",
    "# Perform sentiment analysis on the merged dataset for NB and LR\n",
    "for algorithm in [\"NB\", \"LR\"]:\n",
    "    for representation, vectorizer in vectorizers.items():\n",
    "        print(f\"Algorithm: {algorithm}, Representation: {representation}\")\n",
    "        # Initialize the vectorizer\n",
    "        X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "        X_test_vectorized = vectorizer.transform(X_test)\n",
    "        \n",
    "        # Train the classifier\n",
    "        if algorithm == \"NB\":\n",
    "            classifier = MultinomialNB()\n",
    "        elif algorithm == \"LR\":\n",
    "            classifier = LogisticRegression(max_iter=500, random_state=13)\n",
    "        \n",
    "        classifier.fit(X_train_vectorized, y_train)\n",
    "        \n",
    "        # Predict sentiment\n",
    "        y_pred = classifier.predict(X_test_vectorized)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        precision = precision_score(y_test, y_pred, average=\"binary\")  # Assuming binary classification\n",
    "        recall = recall_score(y_test, y_pred, average=\"binary\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "        \n",
    "        # Store results in the dataframe\n",
    "        results_df = results_df.append(\n",
    "            {\n",
    "                \"Algorithm\": algorithm,\n",
    "                \"Representation\": representation,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1\": f1,\n",
    "            },\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "# Display the results\n",
    "print(\"Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anteia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
